<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Apache Flink结合Kafka构建端到端的Exactly-Once处理 | Kaibo's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.1"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-131716279-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + 'adcf6eb324ad0475bb957857cf925dda';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();</script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Apache Flink结合Kafka构建端到端的Exactly-Once处理</h1><a id="logo" href="/.">Kaibo's Blog</a><p class="description">Real-time big data processing</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Apache Flink结合Kafka构建端到端的Exactly-Once处理</h1><div class="post-meta">Jan 10, 2019<script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><a class="disqus-comment-count" data-disqus-identifier="2019/01/10/flink-kafka-exactly-once/" href="/2019/01/10/flink-kafka-exactly-once/#disqus_thread"></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Apache-Flink应用程序中的Exactly-Once语义"><span class="toc-number">1.</span> <span class="toc-text">Apache Flink应用程序中的Exactly-Once语义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Flink应用程序端到端的Exactly-Once语义"><span class="toc-number">2.</span> <span class="toc-text">Flink应用程序端到端的Exactly-Once语义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#示例Flink应用程序启动预提交阶段"><span class="toc-number">3.</span> <span class="toc-text">示例Flink应用程序启动预提交阶段</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#在Flink中实现两阶段提交Operator"><span class="toc-number">4.</span> <span class="toc-text">在Flink中实现两阶段提交Operator</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">5.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="post-content"><blockquote>
<p>本文翻译自：<a href="https://data-artisans.com/blog/end-to-end-exactly-once-processing-apache-flink-apache-kafka" target="_blank" rel="noopener">https://data-artisans.com/blog/end-to-end-exactly-once-processing-apache-flink-apache-kafka</a></p>
</blockquote>
<p>Apache Flink自2017年12月发布的1.4.0版本开始，为流计算引入了一个重要的里程碑特性：TwoPhaseCommitSinkFunction（<a href="https://issues.apache.org/jira/browse/FLINK-7210" target="_blank" rel="noopener">相关的Jira</a>）。它提取了两阶段提交协议的通用逻辑，使得通过Flink来构建端到端的Exactly-Once程序成为可能。同时支持一些数据源（source）和输出端（sink），包括Apache Kafka 0.11及更高版本。它提供了一个抽象层，用户只需要实现少数方法就能实现端到端的Exactly-Once语义。</p>
<p>有关TwoPhaseCommitSinkFunction的使用详见文档: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/api/java/org/apache/flink/streaming/api/functions/sink/TwoPhaseCommitSinkFunction.html" target="_blank" rel="noopener">TwoPhaseCommitSinkFunction</a>。或者可以直接阅读Kafka 0.11 sink的文档: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/kafka.html#kafka-011" target="_blank" rel="noopener">kafka</a>。</p>
<p>接下来会详细分析这个新功能以及Flink的实现逻辑，分为如下几点。</p>
<ul>
<li>描述Flink checkpoint机制是如何保证Flink程序结果的Exactly-Once的</li>
<li>显示Flink如何通过两阶段提交协议与数据源和数据输出端交互，以提供端到端的Exactly-Once保证</li>
<li>通过一个简单的示例，了解如何使用TwoPhaseCommitSinkFunction实现Exactly-Once的文件输出</li>
</ul>
<h2 id="Apache-Flink应用程序中的Exactly-Once语义"><a href="#Apache-Flink应用程序中的Exactly-Once语义" class="headerlink" title="Apache Flink应用程序中的Exactly-Once语义"></a>Apache Flink应用程序中的Exactly-Once语义</h2><p>当我们说『Exactly-Once』时，指的是每个输入的事件只影响最终结果一次。即使机器或软件出现故障，既没有重复数据，也不会丢数据。</p>
<p><a href="https://zhoukaibo.com/tags/flink/">Flink</a>很久之前就提供了Exactly-Once语义。在过去几年中，我们对Flink的<a href="https://data-artisans.com/blog/high-throughput-low-latency-and-exactly-once-stream-processing-with-apache-flink" target="_blank" rel="noopener">checkpoint机制</a>有过深入的描述，这是Flink有能力提供Exactly-Once语义的核心。Flink文档还提供了该功能的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/ops/state/checkpoints.html" target="_blank" rel="noopener">全面概述</a>。</p>
<p>在继续之前，先看下对checkpoint机制的简要介绍，这对理解后面的主题至关重要。</p>
<p>一次checkpoint是以下内容的一致性快照： </p>
<ul>
<li>应用程序的当前状态</li>
<li>输入流的位置</li>
</ul>
<p>Flink可以配置一个固定的时间点，定期产生checkpoint，将checkpoint的数据写入持久存储系统，例如S3或HDFS。将checkpoint数据写入持久存储是异步发生的，这意味着Flink应用程序在checkpoint过程中可以继续处理数据。</p>
<p>如果发生机器或软件故障，重新启动后，<a href="https://zhoukaibo.com/tags/flink/">Flink</a>应用程序将从最新的checkpoint点恢复处理； Flink会恢复应用程序状态，将输入流回滚到上次checkpoint保存的位置，然后重新开始运行。这意味着Flink可以像从未发生过故障一样计算结果。</p>
<p>在Flink 1.4.0之前，Exactly-Once语义仅限于Flink应用程序内部，并没有扩展到Flink数据处理完后发送的大多数外部系统。Flink应用程序与各种数据输出端进行交互，开发人员需要有能力自己维护组件的上下文来保证Exactly-Once语义。</p>
<p>为了提供端到端的Exactly-Once语义 - 也就是说，除了Flink应用程序内部，Flink写入的外部系统也需要能满足Exactly-Once语义 - 这些外部系统必须提供提交或回滚的方法，然后通过Flink的checkpoint机制来协调。</p>
<p>分布式系统中，协调提交和回滚的常用方法是<a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol" target="_blank" rel="noopener">两阶段提交协议</a>。在下一节中，我们将讨论Flink的TwoPhaseCommitSinkFunction是如何利用两阶段提交协议来提供端到端的Exactly-Once语义。</p>
<h2 id="Flink应用程序端到端的Exactly-Once语义"><a href="#Flink应用程序端到端的Exactly-Once语义" class="headerlink" title="Flink应用程序端到端的Exactly-Once语义"></a>Flink应用程序端到端的Exactly-Once语义</h2><p>我们将介绍两阶段提交协议，以及它如何在一个读写Kafka的Flink程序中实现端到端的Exactly-Once语义。Kafka是一个流行的消息中间件，经常与Flink一起使用。Kafka在最近的0.11版本中添加了对事务的支持。这意味着现在通过Flink读写Kafaka，并提供<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/kafka.html#kafka-011" target="_blank" rel="noopener">端到端的Exactly-Once语义有了必要的支持</a>。</p>
<p><a href="https://zhoukaibo.com/tags/flink/">Flink</a>对端到端的Exactly-Once语义的支持不仅局限于Kafka，您可以将它与任何一个提供了必要的协调机制的源/输出端一起使用。例如<a href="http://pravega.io/" target="_blank" rel="noopener">Pravega</a>，来自DELL/EMC的开源流媒体存储系统，通过Flink的TwoPhaseCommitSinkFunction也能支持端到端的Exactly-Once语义。</p>
<p><img src="https://raw.githubusercontent.com/kaibozhou/kaibozhou.github.io/img/20190428122306.png" alt="exactly-once-two-phase-commit-1"></p>
<p>在今天讨论的这个示例程序中，我们有：</p>
<ul>
<li>从Kafka读取的数据源（Flink内置的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/kafka.html#kafka-consumer" target="_blank" rel="noopener">KafkaConsumer</a>）</li>
<li>窗口聚合</li>
<li>将数据写回Kafka的数据输出端（Flink内置的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/kafka.html#kafka-producer" target="_blank" rel="noopener">KafkaProducer</a>）</li>
</ul>
<p>要使数据输出端提供Exactly-Once保证，它必须将所有数据通过一个事务提交给Kafka。提交捆绑了两个checkpoint之间的所有要写入的数据。这可确保在发生故障时能回滚写入的数据。但是在分布式系统中，通常会有多个并发运行的写入任务的，简单的提交或回滚是不够的，因为所有组件必须在提交或回滚时“一致”才能确保一致的结果。Flink使用两阶段提交协议及预提交阶段来解决这个问题。</p>
<p>在checkpoint开始的时候，即两阶段提交协议的“预提交”阶段。当checkpoint开始时，Flink的JobManager会将checkpoint barrier（将数据流中的记录分为进入当前checkpoint与进入下一个checkpoint）注入数据流。</p>
<p>brarrier在operator之间传递。对于每一个operator，它触发operator的状态快照写入到state backend。</p>
<p><img src="https://raw.githubusercontent.com/kaibozhou/kaibozhou.github.io/img/20190428122328.png" alt="exactly-once-two-phase-commit-2"></p>
<p>数据源保存了消费Kafka的偏移量(offset)，之后将checkpoint barrier传递给下一个operator。</p>
<p>这种方式仅适用于operator具有『内部』状态。所谓内部状态，是指Flink state backend保存和管理的 -例如，第二个operator中window聚合算出来的sum值。当一个进程有它的内部状态的时候，除了在checkpoint之前需要将数据变更写入到state backend，不需要在预提交阶段执行任何其他操作。<a href="https://zhoukaibo.com/tags/flink/">Flink</a>负责在checkpoint成功的情况下正确提交这些写入，或者在出现故障时中止这些写入。</p>
<p><img src="https://raw.githubusercontent.com/kaibozhou/kaibozhou.github.io/img/20190428122346.png" alt="exactly-once-two-phase-commit-3"></p>
<h2 id="示例Flink应用程序启动预提交阶段"><a href="#示例Flink应用程序启动预提交阶段" class="headerlink" title="示例Flink应用程序启动预提交阶段"></a>示例Flink应用程序启动预提交阶段</h2><p>但是，当进程具有『外部』状态时，需要作些额外的处理。外部状态通常以写入外部系统（如Kafka）的形式出现。在这种情况下，为了提供Exactly-Once保证，外部系统必须支持事务，这样才能和两阶段提交协议集成。</p>
<p>在本文示例中的数据需要写入Kafka，因此数据输出端（Data Sink）有外部状态。在这种情况下，在预提交阶段，除了将其状态写入state backend之外，数据输出端还必须预先提交其外部事务。</p>
<p><img src="https://raw.githubusercontent.com/kaibozhou/kaibozhou.github.io/img/20190428122406.png" alt="exactly-once-two-phase-commit-4"></p>
<p>当checkpoint barrier在所有operator都传递了一遍，并且触发的checkpoint回调成功完成时，预提交阶段就结束了。所有触发的状态快照都被视为该checkpoint的一部分。checkpoint是整个应用程序状态的快照，包括预先提交的外部状态。如果发生故障，我们可以回滚到上次成功完成快照的时间点。</p>
<p>下一步是通知所有operator，checkpoint已经成功了。这是两阶段提交协议的提交阶段，JobManager为应用程序中的每个operator发出checkpoint已完成的回调。</p>
<p>数据源和widnow operator没有外部状态，因此在提交阶段，这些operator不必执行任何操作。但是，数据输出端（Data Sink）拥有外部状态，此时应该提交外部事务。</p>
<p><img src="https://raw.githubusercontent.com/kaibozhou/kaibozhou.github.io/img/20190428122426.png" alt="exactly-once-two-phase-commit-5"></p>
<p>我们对上述知识点总结下：</p>
<ul>
<li>一旦所有operator完成预提交，就提交一个commit。</li>
<li>如果至少有一个预提交失败，则所有其他提交都将中止，我们将回滚到上一个成功完成的checkpoint。</li>
<li>在预提交成功之后，提交的commit需要保证最终成功 - operator和外部系统都需要保障这点。如果commit失败（例如，由于间歇性网络问题），整个<a href="https://zhoukaibo.com/tags/flink/">Flink</a>应用程序将失败，应用程序将根据用户的重启策略重新启动，还会尝试再提交。这个过程至关重要，因为如果commit最终没有成功，将会导致数据丢失。</li>
</ul>
<p>因此，我们可以确定所有operator都同意checkpoint的最终结果：所有operator都同意数据已提交，或提交被中止并回滚。</p>
<h2 id="在Flink中实现两阶段提交Operator"><a href="#在Flink中实现两阶段提交Operator" class="headerlink" title="在Flink中实现两阶段提交Operator"></a>在Flink中实现两阶段提交Operator</h2><p>完整的实现两阶段提交协议可能有点复杂，这就是为什么<a href="https://zhoukaibo.com/tags/flink/">Flink</a>将它的通用逻辑提取到抽象类TwoPhaseCommitSinkFunction中的原因。</p>
<p>接下来基于输出到文件的简单示例，说明如何使用TwoPhaseCommitSinkFunction。用户只需要实现四个函数，就能为数据输出端实现Exactly-Once语义：</p>
<ul>
<li>beginTransaction - 在事务开始前，我们在目标文件系统的临时目录中创建一个临时文件。随后，我们可以在处理数据时将数据写入此文件。</li>
<li>preCommit - 在预提交阶段，我们刷新文件到存储，关闭文件，不再重新写入。我们还将为属于下一个checkpoint的任何后续文件写入启动一个新的事务。</li>
<li>commit - 在提交阶段，我们将预提交阶段的文件原子地移动到真正的目标目录。需要注意的是，这会增加输出数据可见性的延迟。</li>
<li>abort - 在中止阶段，我们删除临时文件。</li>
</ul>
<p>我们知道，如果发生任何故障，Flink会将应用程序的状态恢复到最新的一次checkpoint点。一种极端的情况是，预提交成功了，但在这次commit的通知到达operator之前发生了故障。在这种情况下，Flink会将operator的状态恢复到已经预提交，但尚未真正提交的状态。</p>
<p>我们需要在预提交阶段保存足够多的信息到checkpoint状态中，以便在重启后能正确的中止或提交事务。在这个例子中，这些信息是临时文件和目标目录的路径。</p>
<p>TwoPhaseCommitSinkFunction已经把这种情况考虑在内了，并且在从checkpoint点恢复状态时，会优先发出一个commit。我们需要以幂等方式实现提交，一般来说，这并不难。在这个示例中，我们可以识别出这样的情况：临时文件不在临时目录中，但已经移动到目标目录了。</p>
<p>在TwoPhaseCommitSinkFunction中，还有一些其他边界情况也会考虑在内，请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/api/java/org/apache/flink/streaming/api/functions/sink/TwoPhaseCommitSinkFunction.html" target="_blank" rel="noopener">Flink文档</a>了解更多信息。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总结下本文涉及的一些要点：</p>
<ul>
<li><a href="https://zhoukaibo.com/tags/flink/">Flink</a>的checkpoint机制是支持两阶段提交协议并提供端到端的Exactly-Once语义的基础。</li>
<li>这个方案的优点是: Flink不像其他一些系统那样，通过网络传输存储数据 - 不需要像大多数批处理程序那样将计算的每个阶段写入磁盘。</li>
<li>Flink的TwoPhaseCommitSinkFunction提取了两阶段提交协议的通用逻辑，基于此将Flink和支持事务的外部系统结合，构建端到端的Exactly-Once成为可能。</li>
<li>从<a href="https://data-artisans.com/blog/announcing-the-apache-flink-1-4-0-release" target="_blank" rel="noopener">Flink 1.4.0</a>开始，Pravega和Kafka 0.11 producer都提供了Exactly-Once语义；Kafka在0.11版本首次引入了事务，为在Flink程序中使用Kafka producer提供Exactly-Once语义提供了可能性。</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/kafka.html#kafka-011" target="_blank" rel="noopener">Kafaka 0.11 producer</a>的事务是在TwoPhaseCommitSinkFunction基础上实现的，和at-least-once producer相比只增加了非常低的开销。</li>
</ul>
<p>这是个令人兴奋的功能，期待Flink TwoPhaseCommitSinkFunction在未来支持更多的数据接收端。</p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>kaibo</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2019/01/10/flink-kafka-exactly-once/">https://zhoukaibo.com/2019/01/10/flink-kafka-exactly-once/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>转载请保留作者及链接</li></ul></div><br><div class="tags"><a href="/tags/flink/">flink</a><a href="/tags/exactly-once/">exactly-once</a><a href="/tags/at-least-once/">at-least-once</a><a href="/tags/kafka/">kafka</a></div><div class="post-nav"><a class="pre" href="/2019/02/14/exactly-once-exactly-same/">谈谈流计算中的『Exactly Once』特性</a><a class="next" href="/2019/01/10/hello-world/">Hello World</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'https://zhoukaibo.com/2019/01/10/flink-kafka-exactly-once/';
    this.page.identifier = '2019/01/10/flink-kafka-exactly-once/';
    this.page.title = 'Apache Flink结合Kafka构建端到端的Exactly-Once处理';
  };</script><script type="text/javascript" id="disqus-lazy-load-script">$.ajax({
url: 'https://disqus.com/next/config.json',
timeout: 2500,
type: 'GET',
success: function(){
  var d = document;
  var s = d.createElement('script');
  s.src = '//flying5.disqus.com/embed.js';
  s.setAttribute('data-timestamp', + new Date());
  (d.head || d.body).appendChild(s);
  $('.disqus_click_btn').css('display', 'none');
},
error: function() {
  $('.disqus_click_btn').css('display', 'block');
}
});</script><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//flying5.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://flying5.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="https://zhoukaibo.com"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/spi/" style="font-size: 15px;">spi</a> <a href="/tags/flink/" style="font-size: 15px;">flink</a> <a href="/tags/kubernetes/" style="font-size: 15px;">kubernetes</a> <a href="/tags/exactly-once/" style="font-size: 15px;">exactly-once</a> <a href="/tags/at-least-once/" style="font-size: 15px;">at-least-once</a> <a href="/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/tags/yarn/" style="font-size: 15px;">yarn</a> <a href="/tags/k8s/" style="font-size: 15px;">k8s</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/02/18/Flink-1-10-Native-Kubernetes/">Flink 1.10 Native Kubernetes 原理与实践</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/15/flink-yarn-k8s-principle-practice/">Flink on Yarn / Kubernetes 原理剖析及实践</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/15/apache-flink-intro-client/">Apache Flink 客户端操作</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/16/java-spi/">Java SPI 机制分析及其优缺点</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/14/exactly-once-exactly-same/">谈谈流计算中的『Exactly Once』特性</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/10/flink-kafka-exactly-once/">Apache Flink结合Kafka构建端到端的Exactly-Once处理</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/10/hello-world/">Hello World</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> 最近评论</i></div><script type="text/javascript" src="//flying5.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">Kaibo's Blog</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.1" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.1" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.1"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.1"></script></div></body></html>